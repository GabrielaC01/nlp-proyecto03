{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32adc15c",
   "metadata": {},
   "source": [
    "## Informe - Proyecto 3: Tokenización y Embeddings Visuales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2702f4",
   "metadata": {},
   "source": [
    "### Objetivo\n",
    "Analizar cómo diferentes técnicas de tokenización influyen en las representaciones semánticas generadas por modelos de lenguaje basados en Transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07991a34",
   "metadata": {},
   "source": [
    "### Metodología\n",
    "\n",
    "Se trabajó con un corpus de 20 frases en español relacionadas al procesamiento de lenguaje natural. Se compararon dos métodos de tokenización:\n",
    "\n",
    "1. **Tokenización por espacios**: Separación clásica con limpieza básica (minúsculas, eliminación de signos y tildes).\n",
    "2. **Byte-Pair Encoding (BPE)**: Entrenado con SentencePiece sobre el corpus.\n",
    "\n",
    "Luego, se aplicaron los siguientes pasos:\n",
    "\n",
    "- Generación de embeddings usando el modelo `dccuchile/bert-base-spanish-wwm-uncased`\n",
    "- Cálculo de la matriz de similitud coseno para cada tokenización\n",
    "- Proyección 2D mediante PCA para visualizar agrupaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4240ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokenización BPE</th>\n",
       "      <th>Tokenización por Espacios</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Frase 4 - Frase 13 (sim=0.966)</td>\n",
       "      <td>Frase 17 - Frase 19 (sim=0.846)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Frase 4 - Frase 17 (sim=0.956)</td>\n",
       "      <td>Frase 5 - Frase 13 (sim=0.805)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Frase 16 - Frase 20 (sim=0.956)</td>\n",
       "      <td>Frase 13 - Frase 17 (sim=0.722)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Frase 17 - Frase 19 (sim=0.956)</td>\n",
       "      <td>Frase 16 - Frase 17 (sim=0.706)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Frase 4 - Frase 11 (sim=0.955)</td>\n",
       "      <td>Frase 8 - Frase 18 (sim=0.704)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Tokenización BPE        Tokenización por Espacios\n",
       "0   Frase 4 - Frase 13 (sim=0.966)  Frase 17 - Frase 19 (sim=0.846)\n",
       "1   Frase 4 - Frase 17 (sim=0.956)   Frase 5 - Frase 13 (sim=0.805)\n",
       "2  Frase 16 - Frase 20 (sim=0.956)  Frase 13 - Frase 17 (sim=0.722)\n",
       "3  Frase 17 - Frase 19 (sim=0.956)  Frase 16 - Frase 17 (sim=0.706)\n",
       "4   Frase 4 - Frase 11 (sim=0.955)   Frase 8 - Frase 18 (sim=0.704)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cargar matrices de similitud \n",
    "sim_bpe = pd.read_csv(\"resultados/similitud_bpe.csv\", index_col=0)\n",
    "sim_esp = pd.read_csv(\"resultados/similitud_espacios.csv\", index_col=0)\n",
    "\n",
    "# Convertir a matrices numpy\n",
    "mat_bpe = sim_bpe.values\n",
    "mat_esp = sim_esp.values\n",
    "\n",
    "# Rellenar diagonal con -1 para ignorar autocomparación\n",
    "np.fill_diagonal(mat_bpe, -1)\n",
    "np.fill_diagonal(mat_esp, -1)\n",
    "\n",
    "# Función para extraer los top-k pares más similares\n",
    "def obtener_pares_mas_similares(matriz, k=5):\n",
    "    pares = []\n",
    "    for _ in range(k):\n",
    "        i, j = np.unravel_index(np.argmax(matriz), matriz.shape)\n",
    "        valor = matriz[i, j]\n",
    "        pares.append((f\"Frase {i+1} - Frase {j+1} (sim={valor:.3f})\"))\n",
    "        matriz[i, j] = -1  # Evitar repetir\n",
    "        matriz[j, i] = -1\n",
    "    return pares\n",
    "\n",
    "# Extraer resultados\n",
    "pares_bpe = obtener_pares_mas_similares(mat_bpe.copy())\n",
    "pares_esp = obtener_pares_mas_similares(mat_esp.copy())\n",
    "\n",
    "tabla_similares = pd.DataFrame({\n",
    "    \"Tokenización BPE\": pares_bpe,\n",
    "    \"Tokenización por Espacios\": pares_esp\n",
    "})\n",
    "\n",
    "import IPython.display as display\n",
    "display.display(tabla_similares)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e14c337",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "Los resultados evidencian que la técnica de tokenización influye directamente en las representaciones generadas por modelos Transformer\n",
    "\n",
    "- La tokenización BPE permitió al modelo capturar similitudes semánticas de manera más precisa, generando valores más altos en la matriz de similitud coseno entre frases relacionadas\n",
    "\n",
    "- La tokenización por separación de espacios mostró una menor capacidad para agrupar frases similares, con valores de similitud generalmente más bajos\n",
    "\n",
    "Estas diferencias también se reflejan visualmente en los gráficos de PCA, ya que las frases tokenizadas con BPE tienden a formar clústeres más compactos y coherentes, mientras que las generadas por espacios están más dispersas\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
